<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web AR Hand Tracking</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>
    <video id="video" style="display:none" autoplay></video>
    <script>
        // 初始化 Mediapipe Hands
        const hands = new Hands({
            locateFile: (file) => {
                return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
            }
        });

        hands.setOptions({
            maxNumHands: 2,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        // 初始化 Three.js 場景
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // 設置相機位置
        camera.position.z = 5;

        // 添加光源
        const light = new THREE.AmbientLight(0x404040); 
        scene.add(light);

        // 添加綠色點
        const points = [];
        const material = new THREE.MeshBasicMaterial({ color: 0x00ff00 });
        const geometry = new THREE.SphereGeometry(0.05, 32, 32);
        for (let i = 0; i < 21; i++) {
            const point = new THREE.Mesh(geometry, material);
            scene.add(point);
            points.push(point);
        }

        // 使用 Mediapipe 的 CameraUtils 來處理相機
        const videoElement = document.getElementById('video');
        const cameraUtils = new Camera(videoElement, {
            onFrame: async () => {
                await hands.send({ image: videoElement });
            }
        });

        hands.onResults((results) => {
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                const landmarks = results.multiHandLandmarks[0];
                for (let i = 0; i < landmarks.length; i++) {
                    const { x, y, z } = landmarks[i];
                    points[i].position.set((x - 0.5) * 2, (y - 0.5) * -2, -z);
                }
            }
            renderer.render(scene, camera);
        });

        // 啟動相機
        cameraUtils.start();
    </script>
</body>
</html>
