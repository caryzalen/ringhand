<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>MediaPipe Hands Tracking with A-Frame</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            overflow: hidden;
            background: #000;
        }
        #videoElement {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: -1;
        }
        #canvasElement {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 0;
        }
    </style>
</head>
<body>
    <video id="videoElement" playsinline autoplay muted></video>
    <canvas id="canvasElement"></canvas>
    <a-scene>
        <a-entity camera></a-entity>
    </a-scene>
    <script>
        window.onload = () => {
            const videoElement = document.getElementById('videoElement');
            const canvasElement = document.getElementById('canvasElement');
            const ctx = canvasElement.getContext('2d');
            
            const hands = new Hands({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });

            hands.setOptions({
                maxNumHands: 2,
                modelComplexity: 1,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            function onResults(results) {
                ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);
                if (results.image) {
                    ctx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
                }
                if (results.multiHandLandmarks) {
                    for (const landmarks of results.multiHandLandmarks) {
                        drawConnectors(ctx, landmarks, Hands.HAND_CONNECTIONS, {color: '#00FF00', lineWidth: 5});
                        drawLandmarks(ctx, landmarks, {color: '#FF0000', lineWidth: 2});
                    }
                }
            }

            hands.onResults(onResults);

            const camera = new Camera(videoElement, {
                onFrame: async () => {
                    await hands.send({image: videoElement});
                },
                width: window.innerWidth,
                height: window.innerHeight
            });
            camera.start();

            // Resize canvas on window resize
            window.addEventListener('resize', () => {
                canvasElement.width = window.innerWidth;
                canvasElement.height = window.innerHeight;
                camera.start(); // Restart the camera with new dimensions
            });

            // Initial canvas size
            canvasElement.width = window.innerWidth;
            canvasElement.height = window.innerHeight;
        };
    </script>
</body>
</html>
